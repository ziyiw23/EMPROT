{
  "d_embed": 512,
  "num_heads": 8,
  "dropout": 0.1,
  "max_residues": 400,
  "sequence_length": 5,
  "d_k": 64,
  "d_v": 64,
  "use_gradient_checkpointing": false,
  "architecture_notes": "Default EMPROT transformer configuration for baseline model analysis"
} 