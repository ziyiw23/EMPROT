base_config: base_config.yaml

model:
  num_layers: 8          
  future_horizon: 3
  d_embed: 768

data:
  future_horizon: 3
  num_full_res_frames: 5
  history_prefix_frames: 0

training:
  objective: residue_centric

  # residue-centric knobs
  # res_num_samples: 32      # DEPRECATED: now using all valid residues
  res_ce_weight: 2.0
  res_js_weight: 0.1

  # optimization
  learning_rate: 1.0e-4
  label_smoothing: 0.02
  
  # Slowly introduce model's own predictions to bridge train/eval gap
  scheduled_sampling_p: 0.5

  # scheduler (overrides base_config defaults)
  use_scheduler: true
  # Correct update count per epoch: ~150k samples / 4 batch / 32 accum = ~1170 steps
  # However, for "long warmup" stability, we treat this as BATCH count and let the scheduler run long
  estimated_steps_per_epoch: 3125
  # Explicit warmup steps (avoid confusion)
  warmup_steps: 1000
  max_epochs: 10          

  grad_accum_steps: 32
  
  # train_only_proteins removed for full run

experiment:
  run_name: "res_centric_F3_full_dataset"
  tags: ["residue_centric", "full_dataset"]
